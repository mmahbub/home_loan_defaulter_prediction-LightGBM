{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !python3 -m pip install graphviz\n",
    "\n",
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7f67b4ebdb76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Clear cache before running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Clear cache before running\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.externals import joblib\n",
    "# import graphviz\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2e9328d57a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenpyxl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "from scipy import interp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "Lrate = 0.0001 # Learning rate\n",
    "Epoch = 20 # Total training epoch\n",
    "Batch = 20 # Batch size, Iteration = Data size//Batch\n",
    "HidenNum = 5 # Number of hiden layer neurons\n",
    "F_n = 10 # Fold Count\n",
    "\n",
    "# Images loading\n",
    "def load_images_labels_RGB(img_folder, label_file):\n",
    "    with open(label_file) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # skip header\n",
    "        labels = []\n",
    "        images = []\n",
    "        for row in reader:\n",
    "            img_filename = row[0]\n",
    "            img = Image.open(os.path.join(img_folder,img_filename))\n",
    "            if img is not None:\n",
    "                images.append(np.array(img))\n",
    "                labels.append(int(row[1]))\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Import data (normalized)\n",
    "Img_Data, Label_Data = load_images_labels_RGB('train/', 'train.csv')\n",
    "Size_Data = Img_Data.shape\n",
    "Fold_size = Size_Data[0]//F_n\n",
    "Mean_RGB = np.array([128.41563722, 115.24518493, 119.38645491])\n",
    "Std_RGB = np.array([38.55379149, 35.64913446, 39.07419321])\n",
    "Data_Norm = (Img_Data - Mean_RGB)/Std_RGB\n",
    "\n",
    "# Build BPNN\n",
    "Data_in = tf.placeholder(dtype= tf.float32, shape=(None, 32, 32, 3), name=\"inputs\")\n",
    "# Note that the ground truth is one-hot format\n",
    "Data_y = tf.placeholder(dtype= tf.int32, shape=(None), name=\"GroundTue\")\n",
    "Data_y_ = tf.one_hot(Data_y, 2)\n",
    "learningRate = tf.placeholder(tf.float32)\n",
    "'''\n",
    "All the input parameters/data should be fed through\n",
    "placeholder\n",
    "'''\n",
    "Flat_in = tf.reshape(Data_in, [-1, 32*32*3])\n",
    "BPnn = tf.layers.dense(Flat_in, 30, activation=tf.nn.sigmoid, trainable=True, name='Input_L')\n",
    "BPnn = tf.layers.dense(BPnn, 2, activation=tf.nn.sigmoid, trainable=True, name='Output_L')\n",
    "Out_y = tf.identity(BPnn, name = \"prediction\")\n",
    "'''\n",
    "Three layers of NN\n",
    "32*32*3 input\n",
    "30 hiden\n",
    "2 output\n",
    "NN iss defined using module: tf.layers\n",
    "'''\n",
    "# MSE error\n",
    "loss = tf.sqrt(tf.reduce_mean(tf.square(Data_y_ - Out_y)), name=\"loss\")\n",
    "# Set Adam Optimizer\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss, name=\"train_step\")\n",
    "correct_prediction = tf.equal(tf.argmax(Out_y, 1), tf.argmax(Data_y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    per = np.random.permutation(Data_Norm.shape[0])\n",
    "    Shuf_Data_Norm = Data_Norm[per, :, :, :]\n",
    "    Shuf_Label_Data = Label_Data[per]\n",
    "    for Ep_CNT in range(Epoch):\n",
    "        '''\n",
    "        per = np.random.permutation(Data_Norm.shape[0])\n",
    "        Shuf_Data_Norm = Data_Norm[per, :, :, :]\n",
    "        Shuf_Label_Data = Label_Data[per]\n",
    "        '''\n",
    "        Overall_acc = 0.0\n",
    "        Overall_loss = 0.0\n",
    "        for i in range(F_n-1):\n",
    "            DataN_te = Shuf_Data_Norm[Fold_size*i:Fold_size*(i+1), :, :, :]\n",
    "            DataN_tr_1 = Shuf_Data_Norm[0:(Fold_size*i), :, :, :]\n",
    "            DataN_tr_2 = Shuf_Data_Norm[Fold_size*(i+1):, :, :, :]\n",
    "            DataN_tr = np.concatenate((DataN_tr_1,DataN_tr_2))\n",
    "            DataN_te_y = Shuf_Label_Data[Fold_size*i:Fold_size*(i+1)]\n",
    "            DataN_tr_y_1 = Shuf_Label_Data[0:(Fold_size*i)]\n",
    "            DataN_tr_y_2 = Shuf_Label_Data[Fold_size*(i+1):]\n",
    "            DataN_tr_y = np.concatenate((DataN_tr_y_1,DataN_tr_y_2))\n",
    "            \n",
    "            Iteration = DataN_tr.shape[0]//Batch\n",
    "            for it_CNT in range(Iteration):\n",
    "                Data_tr_x = DataN_tr[it_CNT*Batch:(it_CNT+1)*Batch, :, :, :]\n",
    "                Data_tr_y = DataN_tr_y[it_CNT*Batch:(it_CNT+1)*Batch].astype(int)\n",
    "                #depth = 7 # Depth after one-hot conversion\n",
    "                #Data_tr_y_onehot = tf.one_hot(Data_tr_y, depth)\n",
    "                _, batch_loss = sess.run([train_step, loss],feed_dict={Data_in: Data_tr_x, Data_y: Data_tr_y, \n",
    "                                         learningRate:Lrate})\n",
    "                batch_acc = sess.run([accuracy],feed_dict={Data_in: Data_tr_x, Data_y: Data_tr_y, \n",
    "                                     learningRate:Lrate})\n",
    "                '''\n",
    "                print(\"iteration: %d, batch_loss: %.4f, batch_acc: %.4f\"\n",
    "                          % (it_CNT, batch_loss, batch_acc[0]))\n",
    "                '''\n",
    "            Data_va_x = DataN_te[0:100, :, :, :]\n",
    "            Data_va_y = DataN_te_y[0:100].astype(int)\n",
    "            Val_loss, Val_acc = sess.run([loss, accuracy],feed_dict={Data_in: Data_va_x, Data_y: Data_va_y, \n",
    "                                learningRate:Lrate})\n",
    "            Overall_acc = Overall_acc + Val_acc\n",
    "            Overall_loss = Overall_loss + Val_loss\n",
    "            #print(\"Fold: %d, batch_loss: %.4f, batch_acc: %.4f\"\n",
    "            #      % (i, Val_loss, Val_acc))\n",
    "        print(\"Epoch:    %d,  Overall_Accuracy:  %.4f, Overall_loss:  %.4f\"\n",
    "              % ((Ep_CNT+1), Overall_acc/(F_n-1), Overall_loss/(F_n-1)))\n",
    "        DataN_te = Shuf_Data_Norm[Fold_size*9:, :, :, :]\n",
    "        DataN_te_y = Shuf_Label_Data[Fold_size*9:]\n",
    "        Data_te_x = DataN_te[0:100, :, :, :]\n",
    "        Data_te_y = DataN_te_y[0:100].astype(int)\n",
    "        Te_loss, Te_acc = sess.run([loss, accuracy],feed_dict={Data_in: Data_te_x, Data_y: Data_te_y, \n",
    "                                learningRate:Lrate})\n",
    "        print(\"Epoch:   %d, Test_loss: %.4f, Test_acc: %.4f\"\n",
    "              % ((Ep_CNT+1), Te_loss, Te_acc))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
