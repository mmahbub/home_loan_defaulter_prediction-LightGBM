{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !python3 -m pip install tqdm\n",
    "\n",
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "# from tqdm import tqdm_notebook\n",
    "# import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "# import imageio\n",
    "# import cv2\n",
    "import math\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "# from PIL import Image\n",
    "from sklearn import tree\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "F_n = 10 # Fold Count\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from random import sample \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    282682\n",
      "1     24825\n",
      "Name: TARGET, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df=pd.read_csv(\"home_credit_missing_filled_with_mean.csv\")\n",
    "\n",
    "sns.countplot(train_df[\"TARGET\"])\n",
    "print(train_df['TARGET'].value_counts())\n",
    "class_label = train_df['TARGET'].values\n",
    "\n",
    "mat_X_ = train_df.values\n",
    "\n",
    "np.savetxt('augmented_mat.txt',mat_X_,fmt='%.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate covariance and perform eigenvalue decomposition\n",
    "def basis(data):\n",
    "    np.set_printoptions(formatter={'float':\"{:6.6g}\".format})\n",
    "\n",
    "    col = len (data.columns)-1\n",
    "    X = data.iloc[:,0:col].values\n",
    "    y = data.iloc[:,col].values\n",
    "    mat_X = np.matrix(X)    \n",
    "    mu = mat_X.sum(axis = 0)/(len(mat_X)) \n",
    "    mean = np.matrix(mu).T\n",
    "    cls = np.matrix(y).T\n",
    "\n",
    "    covariance_mat = (mat_X - mu).T.dot((mat_X - mu))/(mat_X.shape[0]-1)\n",
    "    print (covariance_mat.shape)\n",
    "    e_values, e_vectors = np.linalg.eig(covariance_mat)\n",
    "    e_pairs = [(np.abs(e_values[i]), e_vectors[:,i]) for i in range(len(e_values))]\n",
    "\n",
    "    # sort from high to low\n",
    "    e_pairs.sort()\n",
    "    e_pairs.reverse()\n",
    "    e_val_mat = np.asmatrix(e_values)\n",
    "    # sort the eigenvalue in the ascending order\n",
    "    e_val_mat.sort()\n",
    "\n",
    "    return mat_X, e_vectors, e_val_mat, e_pairs, cls, e_values\n",
    "\n",
    "mat_X, e_vectors, e_val_mat, e_pairs, cls, e_values= basis (data1)\n",
    "\n",
    "# derive a new set of basis and choose the major axes with variable error rate\n",
    "def PCA(eigen_val_mat,eigen_pairs,normalized_data,error_rate):\n",
    "    psum = 0.0\n",
    "    nf = np.size(eigen_val_mat,1)\n",
    "    for i in range (0, nf):\n",
    "        psum += eigen_val_mat[0, i]\n",
    "    p = 0\n",
    "    sum = 0.0\n",
    "    while sum/psum < error_rate and p < nf:\n",
    "        sum += eigen_val_mat[0,p]\n",
    "        p += 1   \n",
    "    pnf = nf - (p-1)  \n",
    "    print (pnf)\n",
    "    matrix_w = np.hstack((eigen_pairs[i][1].reshape(nf,1))for i in range (0,pnf))\n",
    "    return matrix_w\n",
    "\n",
    "# Represent the data using this new set of basis for a reduced dimension\n",
    "def dimension_reduction(W, data):\n",
    "    col = len (data.columns)-1\n",
    "    x = data.iloc[:,0:col].values\n",
    "    y = data.iloc[:,col].values\n",
    "    mat = np.matrix(x)\n",
    "    classs = np.matrix(y).T\n",
    "\n",
    "    reduced_data = (mat.dot(W))\n",
    "    pX = np.hstack((reduced_data.real,classs))\n",
    "#     print ('\\n Reduced Data: \\n', pX)\n",
    "    return pX\n",
    "\n",
    "# W = PCA (e_val_mat,e_pairs,mat_X,#)\n",
    "# pX = dimension_reduction (W, data1 )\n",
    "# np.savetxt('pFINAL_#.txt',pX,fmt='%.4f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean-vectors for each class\n",
    "def mean_vectors(x, y):\n",
    "    class_ = np.unique(y)\n",
    "    mean_vectors = []\n",
    "    for cls in class_:\n",
    "        mean_vectors.append(np.mean(x[y==cls], axis=0))\n",
    "    return mean_vectors\n",
    "\n",
    "# calculate the within class scatter matrix \n",
    "def scatter_within(x, y):\n",
    "    class_ = np.unique(y)\n",
    "    n_col = x.shape[1]\n",
    "    mean = mean_vectors(x, y)\n",
    "    Sw = np.zeros((n_col, n_col))\n",
    "    for cls, mean_vec in zip(class_, mean):\n",
    "        Sc = np.zeros((n_col, n_col))                 \n",
    "        for row in x[y == cls]:\n",
    "            row, mean_vec = row.reshape(n_col, 1), mean_vec.reshape(n_col, 1)\n",
    "            Sc += (row-mean_vec).dot((row-mean_vec).T)\n",
    "        Sw += Sc   \n",
    "    return Sw\n",
    "\n",
    "# create W matrix\n",
    "def create_w (train_data):\n",
    "    col = len (train_data.columns)-1\n",
    "    x = train_data.iloc[:,0:col].values\n",
    "    y = train_data.iloc[:,col].values\n",
    "    mean_vec = mean_vectors(x, y)\n",
    "    Sw = scatter_within(x, y)\n",
    "    W = (np.linalg.inv(Sw)).dot(mean_vec[0]-mean_vec[1])\n",
    "    W_mat = np.matrix(W).T\n",
    "    return W_mat\n",
    "    \n",
    "# build LDA model with mean and Sw    \n",
    "def LDA(data, W_mat):\n",
    "    col = len (data.columns)-1\n",
    "    x = data.iloc[:,0:col].values\n",
    "    y = data.iloc[:,col].values\n",
    "    mat = np.matrix(x)\n",
    "    classs = np.matrix(y).T\n",
    "\n",
    "    reduced_data = mat.dot(W_mat)\n",
    "    fX = np.hstack((reduced_data.real,classs))\n",
    "#     print ('\\n Reduced Data: \\n', fX)\n",
    "    return fX\n",
    "\n",
    "# W_mat = create_w (data1)\n",
    "# fX = LDA (data1,W_mat )\n",
    "# np.savetxt('fFINAL.txt',fX,fmt='%.8f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised\n",
    "### MPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mle (data,a,b):\n",
    "    df = pd.DataFrame(data,index = None, columns = list(range (len(data[0]))) )\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    col = len (df.columns)-1\n",
    "    X = df.iloc[:,0:col].values\n",
    "    Y = df.iloc[:,col].values\n",
    "        \n",
    "    class0 = df.loc[(df[col] == 0)]\n",
    "    class1 = df.loc[(df[col] == 1)]\n",
    "\n",
    "    col0 = len (class0.columns)-1\n",
    "    X0 = class0.iloc[:,0:col0].values\n",
    "    mat0 = np.matrix(X0)    \n",
    "\n",
    "    col1 = len (class1.columns)-1\n",
    "    X1 = class1.iloc[:,0:col1].values\n",
    "    mat1 = np.matrix(X1)  \n",
    "\n",
    "    class_type = np.unique(Y)\n",
    "    n_classes = class_type.shape[0]\n",
    "    mean_vectors = []\n",
    "    for cls in class_type:\n",
    "        mean_vectors.append(np.mean(X[Y==cls], axis=0))\n",
    "    \n",
    "    mu0 = mean_vectors[0]\n",
    "    mu1 = mean_vectors[1]\n",
    "    cov0 = ((mat0 - mu0).T.dot((mat0 - mu0)))/mat0.shape[0]\n",
    "    cov1 = ((mat1 - mu1).T.dot((mat1 - mu1)))/mat1.shape[0]\n",
    "\n",
    "    # find covariance matrices for CASE I\n",
    "    I = np.identity(col)\n",
    "    sigma3 = cov0[a,b]*I\n",
    "\n",
    "    cov_vectors = [cov0,cov1,sigma3] \n",
    "    dim_data = df.shape[0]\n",
    "    dim_class0 = class0.shape[0]\n",
    "    dim_class1 = class1.shape[0]\n",
    "\n",
    "    return mean_vectors, cov_vectors, dim_data, dim_class0,dim_class1\n",
    "\n",
    "\n",
    "#implement mpp\n",
    "def mpp(data_te,mean1,mean2,detClass1,detClass2,invClass1,invClass2,probClass1):\n",
    "    probClass2 = 1-probClass1\n",
    "    df = pd.DataFrame(data_te,index = None, columns = list(range (len(data_te[0]))) )\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    col = len (df.columns)\n",
    "    X = df.iloc[:,0:col].values\n",
    "\n",
    "    # create a matrix from test data for calculation\n",
    "    testSet = np.matrix(X)\n",
    "\n",
    "    n = testSet.shape[1]\n",
    "    \n",
    "    predictedMatrix = np.zeros((testSet.shape[0], 2))\n",
    "    \n",
    "    bestAccuracy = 0\n",
    "    correctGuesses = 0\n",
    "    line1 = np.zeros((1, n-1))\n",
    "    for i in range(testSet.shape[0]):\n",
    "        for j in range (n-1):\n",
    "            line1[:,j] = testSet[i,j]\n",
    "\n",
    "        line2 = line1.T\n",
    "        mahalanobis = line2 - mean1\n",
    "        mahalanobis1 = mahalanobis.T\n",
    "        mahalanobis2 = mahalanobis1 * invClass1\n",
    "        mahalanobis3 = mahalanobis2 * (line2 - mean1)\n",
    "        varMahalanobis = float(-0.5 * mahalanobis3[0][0])\n",
    "        probIsClass1 = float((1.0 / math.sqrt(2 * math.pi * detClass1)) * math.exp(varMahalanobis) * (probClass1))\n",
    "\n",
    "        mahalanobiss = line2 - mean2\n",
    "        mahalanobiss1 = mahalanobiss.T\n",
    "        mahalanobiss2 = mahalanobiss1 * invClass2\n",
    "        mahalanobiss3 = mahalanobiss2 * (line2 - mean2)\n",
    "        varMahalanobiss = float(-0.5 * mahalanobiss3[0][0])\n",
    "\n",
    "        probIsClass2 = float((1.0 / math.sqrt(2 * math.pi * detClass2)) * math.exp(varMahalanobiss) * (probClass2))\n",
    "\n",
    "        predictedClass = 0\n",
    "        if probIsClass2 > probIsClass1:\n",
    "            predictedClass = 1\n",
    "\n",
    "        if predictedClass == testSet[i,n-1]: \n",
    "            correctGuesses+=1\n",
    "\n",
    "        error = float(min(probIsClass2, probIsClass1))\n",
    "\n",
    "        predictedMatrix[i][1] = error\n",
    "        predictedMatrix[i][0] = predictedClass\n",
    "            \n",
    "#         print (correctGuesses) \n",
    "#     print (len(testSet))\n",
    "    acc = float(correctGuesses) / float(len(testSet))\n",
    "    if acc > bestAccuracy:\n",
    "        bestAccuracy = acc\n",
    "\n",
    "    return testSet,predictedMatrix, bestAccuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate TP,TN,FP,FN values\n",
    "def performance_measure(testSet, predictedMatrix):\n",
    "    n = testSet.shape[1]\n",
    "    true_class = []\n",
    "    predicted_class = []\n",
    "\n",
    "    for i in range(testSet.shape[0]):\n",
    "        true = testSet[i,n-1]\n",
    "        true_class.append(true)\n",
    "        \n",
    "    for i in range(predictedMatrix.shape[0]):\n",
    "        predicted = predictedMatrix[i,0]\n",
    "        predicted_class.append(predicted)\n",
    "        \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    posneg = []\n",
    "    for i in range(len(predicted_class)): \n",
    "        if true_class[i]==predicted_class[i]==1:\n",
    "            TP += 1\n",
    "        if predicted_class[i]==1 and true_class[i]!=predicted_class[i]:\n",
    "            FP += 1\n",
    "        if true_class[i]==predicted_class[i]==0:\n",
    "            TN += 1\n",
    "        if predicted_class[i]==0 and true_class[i]!=predicted_class[i]:\n",
    "            FN += 1\n",
    "\n",
    "    posneg.append(TP)\n",
    "    posneg.append(FP)\n",
    "    posneg.append(TN)\n",
    "    posneg.append(FN)\n",
    "    \n",
    "    \n",
    "    return posneg\n",
    "\n",
    "#calculate sensitivity,specificity, TPR, FPR\n",
    "def accuracy(performance_list):\n",
    "    sensitivity = performance_list[0]/(performance_list[0]+performance_list[3])\n",
    "    specificity = performance_list[2]/(performance_list[2]+performance_list[1])\n",
    "    TPR = sensitivity\n",
    "    FPR = 1 - specificity\n",
    "    roc = [sensitivity,specificity, TPR, FPR]\n",
    "    return roc\n",
    "\n",
    "#calculate accuracy (the probability of a correct decision)\n",
    "def getAccuracy(performance_list):\n",
    "    acc = (performance_list[0]+performance_list[2])/sum(performance_list)\n",
    "    \n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold validation on the training set\n",
    "#split the training set into train and test \n",
    "def kfold_split(n_split, x_len):\n",
    "    index = []\n",
    "    test_size = int(x_len/n_split)\n",
    "    train_size = x_len - test_size\n",
    "    for i in range(n_split):\n",
    "        j = i*test_size\n",
    "        index.append([list(set(list(range(0,x_len))).difference(set(list(range(j,j+test_size)))) ),\n",
    "                     list(range(j,j+test_size))])\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement MPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile (filename):\n",
    "    fileData1 = open(filename, \"r\")#,encoding='utf-8-sig')\n",
    "    lines = fileData1.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        x = line.split(',')\n",
    "        data.append(x)\n",
    "    return data\n",
    "\n",
    "def det (mat,n):\n",
    "    (sign, logdet) = np.linalg.slogdet(mat)\n",
    "    s = sign * np.exp(logdet/n)\n",
    "    return s\n",
    "\n",
    "#get mean accuracy of all K-folds for diffrent k in KNN\n",
    "def cross_validation_score(trainingSet, n_split,n):\n",
    "    train = pd.DataFrame(trainingSet)\n",
    "    col = len (train.columns)\n",
    "    X = train.iloc[:,0:col].values\n",
    "    index = kfold_split(n_split, len(X))\n",
    "    acc1 = []\n",
    "    acc2 = []\n",
    "    acc3 = []\n",
    "    \n",
    "    t1 = []\n",
    "    f1 = []\n",
    "    t2 = []\n",
    "    f2 = []\n",
    "    t3 = []\n",
    "    f3 = []\n",
    "\n",
    "    count = 0\n",
    "    for train_index, test_index in index:\n",
    "        count += 1\n",
    "        print ('\\nfold: ',count)\n",
    "        \n",
    "        x = X[train_index]\n",
    "        y = X[test_index]\n",
    "        \n",
    "        # uncomment this line for output\n",
    "#         print (x.tolist())\n",
    "        mean_vectors, cov_vectors,dim_data, dim_class0,dim_class1  = gaussian_mle (x.tolist(),0,0)\n",
    "        mean1 = np.matrix(mean_vectors[0]).T\n",
    "        mean2 = np.matrix(mean_vectors[1]).T\n",
    "        cov0 = cov_vectors[0]\n",
    "        cov1 = cov_vectors[1]\n",
    "        cov2 = cov_vectors [2]\n",
    "\n",
    "        # calculate determinant and inverse of new covariance Matrix (case 1: covariance matrices are equal to (sigma^2)I)\n",
    "        detClass1 = det (cov2,n) #np.linalg.det(cov2)\n",
    "        detClass2 = detClass1\n",
    "        invClass1 = np.linalg.inv(cov2)\n",
    "        invClass2 = invClass1\n",
    "\n",
    "        # calculate determinant and inverse of new covariance matrices (case 2: covariance matrices is equal)\n",
    "        detClass12 = det (cov1,n) #np.linalg.det(cov1)\n",
    "        detClass22 = detClass12\n",
    "        invClass12 = np.linalg.inv(cov1)\n",
    "        invClass22 = invClass12\n",
    "        \n",
    "        # calculate determinant and inverse of new covariance matrices (case 3: covariance matrices are different)\n",
    "        detClass13 = det (cov0,n) #np.linalg.det(cov0)\n",
    "        invClass13 = np.linalg.inv(cov0)\n",
    "        invClass23 = np.linalg.inv(cov1)\n",
    "        detClass23 = det (cov1,n) #np.linalg.det(cov1)\n",
    "#         print (detClass13)\n",
    "#         print (detClass23)\n",
    "\n",
    "        testSet1,predictedMatrix1,bestAccuracy1 = mpp(y.tolist(),mean1,mean2,detClass1,detClass2,invClass1,invClass2,dim_class0/dim_data)\n",
    "        case1 = performance_measure(testSet1, predictedMatrix1)\n",
    "        per_list1 = accuracy(case1)\n",
    "        \n",
    "        classificationAccuracy1 = getAccuracy(case1)\n",
    "        tpr1 = accuracy(per_list1)[2]\n",
    "        fpr1 = accuracy(per_list1)[3]\n",
    "        t1.append(tpr1)\n",
    "        f1.append(fpr1)\n",
    "        print (\"\\nCASE I\")\n",
    "        print (classificationAccuracy1)\n",
    "        acc1.append(classificationAccuracy1)\n",
    "#         class_acc1+=bestAccuracy1\n",
    "        \n",
    "        testSet2,predictedMatrix2,bestAccuracy2 = mpp(y.tolist(), mean1,mean2,detClass12,detClass22,invClass12,invClass22,dim_class0/dim_data)\n",
    "        case2 = performance_measure(testSet2, predictedMatrix2)\n",
    "        per_list2 = accuracy(case2)\n",
    "        classificationAccuracy2 = getAccuracy(case2)\n",
    "        roc2 = accuracy(per_list2)\n",
    "        tpr2 = accuracy(per_list2)[2]\n",
    "        fpr2 = accuracy(per_list2)[3]\n",
    "        t2.append(tpr2)\n",
    "        f2.append(fpr2)\n",
    "        print (\"\\nCASE II\")\n",
    "        print (classificationAccuracy2)\n",
    "#         print (bestAccuracy2)\n",
    "        \n",
    "        acc2.append(classificationAccuracy2)\n",
    "#         class_acc2+=bestAccuracy2\n",
    "\n",
    "        testSet3,predictedMatrix3,bestAccuracy3 = mpp(y.tolist(),mean1,mean2,detClass13,detClass23,invClass13,invClass23,dim_class0/dim_data)\n",
    "        case3 = performance_measure(testSet3, predictedMatrix3)\n",
    "        per_list3 = accuracy(case3)\n",
    "        tpr3 = accuracy(per_list3)[2]\n",
    "        fpr3 = accuracy(per_list3)[3]\n",
    "\n",
    "        classificationAccuracy3 = getAccuracy(case3)\n",
    "        roc3 = accuracy(per_list3)\n",
    "        t3.append(tpr3)\n",
    "        f3.append(fpr3)\n",
    "        print (\"\\nCASE III\")\n",
    "        print (classificationAccuracy3)\n",
    "        acc3.append(classificationAccuracy3)\n",
    "\n",
    "    avg1 = (sum(acc1)/len(acc1))*100\n",
    "    print('\\n CASE I accuracy: ',avg1)\n",
    "    print ('\\n CASE I TPR: ', t1)\n",
    "    print ('\\n CASE I FPR: ', f1)\n",
    "\n",
    "    avg2 = (sum(acc2)/len(acc2))*100\n",
    "    print('\\n CASE II accuracy: ',avg2)\n",
    "    print ('\\n CASE II TPR: ', t2)\n",
    "    print ('\\n CASE II FPR: ', f2)\n",
    "\n",
    "    avg3 = (sum(acc3)/len(acc3))*100\n",
    "    print('\\n CASE III accuracy: ',avg3)\n",
    "    print ('\\n CASE III TPR: ', t3)\n",
    "    print ('\\n CASE III FPR: ', f3)\n",
    "\n",
    "    return avg1,avg2,avg3\n",
    "\n",
    "# data2 = openfile ('pFINAL_.01.txt')\n",
    "# cross_validation_score(data2, 5,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Unable to parse string \"61501.0000 171329.0000 0.0000 0.0000 1.0000 0.0000 0.0000 180000.0000 409500.0000 32350.5000 409500.0000 0.0182 -11371.0000 -2645.0000 -5319.0000 -3776.0000 15.0000 1.0000 1.0000 0.0000 1.0000 1.0000 0.0000 2.0000 3.0000 3.0000 13.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5021 0.3911 0.2021 0.1072 0.1858 0.9866 0.8164 0.0161 0.0000 0.2759 0.1667 0.2083 0.1033 0.0874 0.1107 0.0000 0.0000 0.1092 0.1928 0.9866 0.8236 0.0162 0.0000 0.2759 0.1667 0.2083 0.1057 0.0955 0.1153 0.0000 0.0000 0.1083 0.1858 0.9866 0.8189 0.0162 0.0000 0.2759 0.1667 0.2083 0.1051 0.0889 0.1127 0.0000 0.0000 0.0958 0.0000 0.0000 0.0000 0.0000 -1670.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.2326 0.4396 90000.0000 0.1797 0.0790 2.2750 -1359.0000 -23.0000 -616.0000 266086.8889 -993.0000 9899.0000 1611.7000 9211548.4556 -905.0000 -20.0000 -350.2000 167945.9556 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 424.1250 719528.0625 0.0000 1260000.0000 435531.1500 180157681953.2249 4355311.5000 0.0000 435942.0000 94292.2500 29149644137.1750 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 207.0000 0.5000 5.0000 0.0000 0.0000 0.5000 5.0000 0.0000 0.0000 0.0000 0.0000 1.0000 10.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8000 8.0000 0.2000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -513.0000 -23.0000 -160.8000 44440.2000 708.0000 1798.0000 1265.2000 217491.7000 -45.0000 -20.0000 -27.6000 105.3000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 45000.0000 981000.0000 347712.3000 166595795856.4500 1738561.5000 0.0000 435942.0000 141438.3750 39691711818.5625 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 28.0000 -1359.0000 -834.0000 -1071.2000 36237.7000 -993.0000 9899.0000 1958.2000 20208336.7000 -905.0000 -75.0000 -672.8000 117596.2000 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 565.5000 0.0000 1260000.0000 523350.0000 219478612500.0000 2616750.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 179.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 213832.6498 388400.3682 295891.1004 240267.3266 434778.8206 331420.6578 0.8680 inf inf 256229.7745 417968.3891 333971.9569 11.6039 13.2713 12.4195 -983.9386 -728.6427 -847.7647 48.7154 -54.0000 -3.0000 -36.0556 18.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8333 15.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.1111 2.0000 0.0000 0.0000 0.0000 0.0000 0.0556 1.0000 0.0000 0.0000 0.0000 0.0000 18.0000 2.0000 0.0000 0.0000 0.0000 0.0000 2.0000 55.0000 14.9333 224.0000 1.0000 1.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 71147.0700 14677.8840 220168.2600 8611.3350 71147.0700 14677.8840 220168.2600 -1655.0000 -122.0000 -1224.1333 -18362.0000 15.0000\\n\" at position 0', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"61501.0000 171329.0000 0.0000 0.0000 1.0000 0.0000 0.0000 180000.0000 409500.0000 32350.5000 409500.0000 0.0182 -11371.0000 -2645.0000 -5319.0000 -3776.0000 15.0000 1.0000 1.0000 0.0000 1.0000 1.0000 0.0000 2.0000 3.0000 3.0000 13.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5021 0.3911 0.2021 0.1072 0.1858 0.9866 0.8164 0.0161 0.0000 0.2759 0.1667 0.2083 0.1033 0.0874 0.1107 0.0000 0.0000 0.1092 0.1928 0.9866 0.8236 0.0162 0.0000 0.2759 0.1667 0.2083 0.1057 0.0955 0.1153 0.0000 0.0000 0.1083 0.1858 0.9866 0.8189 0.0162 0.0000 0.2759 0.1667 0.2083 0.1051 0.0889 0.1127 0.0000 0.0000 0.0958 0.0000 0.0000 0.0000 0.0000 -1670.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.2326 0.4396 90000.0000 0.1797 0.0790 2.2750 -1359.0000 -23.0000 -616.0000 266086.8889 -993.0000 9899.0000 1611.7000 9211548.4556 -905.0000 -20.0000 -350.2000 167945.9556 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 424.1250 719528.0625 0.0000 1260000.0000 435531.1500 180157681953.2249 4355311.5000 0.0000 435942.0000 94292.2500 29149644137.1750 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 207.0000 0.5000 5.0000 0.0000 0.0000 0.5000 5.0000 0.0000 0.0000 0.0000 0.0000 1.0000 10.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8000 8.0000 0.2000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -513.0000 -23.0000 -160.8000 44440.2000 708.0000 1798.0000 1265.2000 217491.7000 -45.0000 -20.0000 -27.6000 105.3000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 45000.0000 981000.0000 347712.3000 166595795856.4500 1738561.5000 0.0000 435942.0000 141438.3750 39691711818.5625 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 28.0000 -1359.0000 -834.0000 -1071.2000 36237.7000 -993.0000 9899.0000 1958.2000 20208336.7000 -905.0000 -75.0000 -672.8000 117596.2000 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 565.5000 0.0000 1260000.0000 523350.0000 219478612500.0000 2616750.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 179.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 213832.6498 388400.3682 295891.1004 240267.3266 434778.8206 331420.6578 0.8680 inf inf 256229.7745 417968.3891 333971.9569 11.6039 13.2713 12.4195 -983.9386 -728.6427 -847.7647 48.7154 -54.0000 -3.0000 -36.0556 18.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8333 15.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.1111 2.0000 0.0000 0.0000 0.0000 0.0000 0.0556 1.0000 0.0000 0.0000 0.0000 0.0000 18.0000 2.0000 0.0000 0.0000 0.0000 0.0000 2.0000 55.0000 14.9333 224.0000 1.0000 1.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 71147.0700 14677.8840 220168.2600 8611.3350 71147.0700 14677.8840 220168.2600 -1655.0000 -122.0000 -1224.1333 -18362.0000 15.0000\n\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5b3d9efd0f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'augmented_mat.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_validation_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-035fd51b8b24>\u001b[0m in \u001b[0;36mcross_validation_score\u001b[0;34m(trainingSet, n_split, n)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# uncomment this line for output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#         print (x.tolist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmean_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_class0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_class1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgaussian_mle\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mmean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmean2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b20c5b7240c1>\u001b[0m in \u001b[0;36mgaussian_mle\u001b[0;34m(data, a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgaussian_mle\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m                                       *self.args, **self.kwds)\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameRowApply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             values = lib.maybe_convert_numeric(values, set(),\n\u001b[0;32m--> 133\u001b[0;31m                                                coerce_numeric=coerce_numeric)\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Unable to parse string \"61501.0000 171329.0000 0.0000 0.0000 1.0000 0.0000 0.0000 180000.0000 409500.0000 32350.5000 409500.0000 0.0182 -11371.0000 -2645.0000 -5319.0000 -3776.0000 15.0000 1.0000 1.0000 0.0000 1.0000 1.0000 0.0000 2.0000 3.0000 3.0000 13.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5021 0.3911 0.2021 0.1072 0.1858 0.9866 0.8164 0.0161 0.0000 0.2759 0.1667 0.2083 0.1033 0.0874 0.1107 0.0000 0.0000 0.1092 0.1928 0.9866 0.8236 0.0162 0.0000 0.2759 0.1667 0.2083 0.1057 0.0955 0.1153 0.0000 0.0000 0.1083 0.1858 0.9866 0.8189 0.0162 0.0000 0.2759 0.1667 0.2083 0.1051 0.0889 0.1127 0.0000 0.0000 0.0958 0.0000 0.0000 0.0000 0.0000 -1670.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 1.0000 0.0000 0.2326 0.4396 90000.0000 0.1797 0.0790 2.2750 -1359.0000 -23.0000 -616.0000 266086.8889 -993.0000 9899.0000 1611.7000 9211548.4556 -905.0000 -20.0000 -350.2000 167945.9556 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 424.1250 719528.0625 0.0000 1260000.0000 435531.1500 180157681953.2249 4355311.5000 0.0000 435942.0000 94292.2500 29149644137.1750 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 207.0000 0.5000 5.0000 0.0000 0.0000 0.5000 5.0000 0.0000 0.0000 0.0000 0.0000 1.0000 10.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8000 8.0000 0.2000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -513.0000 -23.0000 -160.8000 44440.2000 708.0000 1798.0000 1265.2000 217491.7000 -45.0000 -20.0000 -27.6000 105.3000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 45000.0000 981000.0000 347712.3000 166595795856.4500 1738561.5000 0.0000 435942.0000 141438.3750 39691711818.5625 565753.5000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 28.0000 -1359.0000 -834.0000 -1071.2000 36237.7000 -993.0000 9899.0000 1958.2000 20208336.7000 -905.0000 -75.0000 -672.8000 117596.2000 0.0000 0.0000 0.0000 0.0000 0.0000 1696.5000 565.5000 0.0000 1260000.0000 523350.0000 219478612500.0000 2616750.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 179.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.5000 1.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 1.0000 2.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.5000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 10986.3450 9798.8400 2820336.2501 106654.5000 119938.5000 113296.5000 88232328.0000 85320.0000 119938.5000 102629.2500 599220271.1250 1.0000 1.2501 1.1250 0.0313 0.0000 21334.5000 10667.2500 227580445.1250 106654.5000 119938.5000 113296.5000 88232328.0000 14.0000 16.0000 15.0000 2.0000 0.0000 0.2179 0.1089 0.0237 -1670.0000 -229.0000 -949.5000 1038240.5000 12.0000 12.0000 12.0000 0.0000 24.0000 213832.6498 388400.3682 295891.1004 240267.3266 434778.8206 331420.6578 0.8680 inf inf 256229.7745 417968.3891 333971.9569 11.6039 13.2713 12.4195 -983.9386 -728.6427 -847.7647 48.7154 -54.0000 -3.0000 -36.0556 18.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.8333 15.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.1111 2.0000 0.0000 0.0000 0.0000 0.0000 0.0556 1.0000 0.0000 0.0000 0.0000 0.0000 18.0000 2.0000 0.0000 0.0000 0.0000 0.0000 2.0000 55.0000 14.9333 224.0000 1.0000 1.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8611.3350 71147.0700 14677.8840 220168.2600 8611.3350 71147.0700 14677.8840 220168.2600 -1655.0000 -122.0000 -1224.1333 -18362.0000 15.0000\\n\" at position 0', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "data = openfile ('augmented_mat.txt')\n",
    "\n",
    "cross_validation_score(data, 5,100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised\n",
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile (filename):\n",
    "    fileData1 = open(filename, \"r\")#,encoding='utf-8-sig')\n",
    "    lines = fileData1.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        data.append(x)\n",
    "    n = len(data[0])-1\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df = df1[df1.columns[:-1]]\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    d = df1[[n]].copy()\n",
    "    cls = d[n]\n",
    "    col=len(df)\n",
    "    A = df.iloc[:,0:col].values\n",
    "\n",
    "    return A,cls\n",
    "\n",
    "def euclidean_dist(point1, point2):\n",
    "    d = np.sum(np.square(point2-point1))\n",
    "    return (np.sqrt(d))\n",
    "\n",
    "\"\"\"Takes the X matrix and the centroids. Then measures the shortest \n",
    "distances between them and returns a vector of cluster indices per sample in X\"\"\"\n",
    "def closest_centroids(X, centroid):\n",
    "    id_ = np.zeros((X.shape[0],1))\n",
    "    \n",
    "    #Loop through each sample in X\n",
    "    for x in range(id_.shape[0]):\n",
    "        point = X[x]\n",
    "        #measure distance of this point from each centroid,\n",
    "        #Keep track of shortest distance and index of shortest distance\n",
    "        min_dist, idx = 255, 0\n",
    "        for i in range(centroid.shape[0]):\n",
    "            centroid_ = centroid[i]\n",
    "            dist = euclidean_dist(centroid_,point)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                idx = i\n",
    "        #modify the index vector with new id\n",
    "        id_[x] = idx\n",
    "        \n",
    "    return id_\n",
    "\n",
    "\n",
    "\"\"\"Takes X matrix and index vector to compute new centroids\"\"\"\n",
    "def new_centroids(X, id_):\n",
    "    new = []\n",
    "    for x in range(len(np.unique(id_))):\n",
    "        new.append(np.array([X[i] for i in range(X.shape[0]) if id_[i] == x]))\n",
    "    return np.array([np.mean(y,axis=0) for y in new])\n",
    "\n",
    "\n",
    "\"\"\"Implement k-means all at once \"\"\"\n",
    "def kmeans(X, initial_centroids, k,n_iter):\n",
    "    current_centroids = initial_centroids\n",
    "    id_ = closest_centroids(X,current_centroids)\n",
    "    current_centroids = new_centroids(X,id_)\n",
    "    curr_cent = np.array (current_centroids)\n",
    "    prev_cent = np.array(initial_centroids)\n",
    "#     print (curr_cent)\n",
    "    ite = 0\n",
    "    while not np.array_equal (prev_cent,curr_cent) and ite < n_iter:\n",
    "        ite += 1\n",
    "        print (ite)\n",
    "        prev_centroids = []\n",
    "        prev_centroids.append(current_centroids)\n",
    "        prev_cent = np.array(prev_centroids)\n",
    "        id_ = closest_centroids(X,current_centroids)\n",
    "        current_centroids = new_centroids(X,id_)\n",
    "        curr_cent = np.array (current_centroids)\n",
    "        \n",
    "    return id_, prev_centroids\n",
    "\n",
    "\"\"\"Initialize k random centroids\"\"\"\n",
    "def k_random_centroids(X, k):\n",
    "    random_indices = sample(range(0,X.shape[0]),k)\n",
    "    return np.array([X[i] for i in random_indices])\n",
    "\n",
    "\n",
    "def clustering(A,k,n_iter):\n",
    "    id_, prev_centroids = kmeans(A,k_random_centroids(A,k), k,n_iter)\n",
    "    id_ = closest_centroids(A, prev_centroids[-1])\n",
    "    return id_\n",
    "\n",
    "#calculate TP,TN,FP,FN values\n",
    "def performance_measure(true_label, clustered_output):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    posneg = []\n",
    "    for i in range(len(clustered_output)): \n",
    "        if true_label[i]==clustered_output[i]==1:\n",
    "            TP += 1\n",
    "        if clustered_output[i]==1 and true_label[i]!=clustered_output[i]:\n",
    "            FP += 1\n",
    "        if true_label[i]==clustered_output[i]==0:\n",
    "            TN += 1\n",
    "        if clustered_output[i]==0 and true_label[i]!=clustered_output[i]:\n",
    "            FN += 1\n",
    "\n",
    "    posneg.append(TP)\n",
    "    posneg.append(FP)\n",
    "    posneg.append(TN)\n",
    "    posneg.append(FN)\n",
    "    \n",
    "    confusion_mat = np.array([[TN,FP],[FN,TP]])\n",
    "    return posneg, confusion_mat\n",
    "\n",
    "\n",
    "#calculate sensitivity,specificity, TPR, FPR\n",
    "def perf_list(true_label, clustered_output):\n",
    "    performance_list,confusion_mat = performance_measure(true_label, clustered_output)\n",
    "    sensitivity = performance_list[0]/(performance_list[0]+performance_list[3])\n",
    "    specificity = performance_list[2]/(performance_list[2]+performance_list[1])\n",
    "    TPR = sensitivity\n",
    "    FPR = 1 - specificity\n",
    "    roc = [sensitivity,specificity, TPR, FPR]\n",
    "    return roc\n",
    "\n",
    "\n",
    "#calculate accuracy (the probability of a correct decision)\n",
    "def accuracy_score(true_label, clustered_output):\n",
    "    performance_list,confusion_mat = performance_measure(true_label, clustered_output)\n",
    "    acc = (performance_list[0]+performance_list[2])/sum(performance_list)\n",
    "    return acc, confusion_mat\n",
    "\n",
    "def ground_truth(label):\n",
    "    true_label = (label.apply(pd.to_numeric)).tolist()\n",
    "    return true_label\n",
    "\n",
    "def accuracy (filename):\n",
    "    A,label = openfile(filename)\n",
    "    predictions = clustering (A,2,10)\n",
    "    km_out = [x[0] for x in predictions.tolist()]\n",
    "    km_output_changed = (pd.DataFrame(km_out)).replace([1, 0], [0, 1])\n",
    "    km_output_changed = [x[0] for x in km_output_changed.values.tolist()]\n",
    "    true_label = ground_truth(label)\n",
    "    roc_org = perf_list(true_label, km_out)\n",
    "    roc_chng = perf_list(true_label, km_output_changed)\n",
    "    ac_result,confusion_mat_org = accuracy_score(true_label, km_out)\n",
    "    ac_manipulated,confusion_mat_manipulated = accuracy_score(true_label, km_output_changed)\n",
    "    print ('ROC_org: ', roc_org)\n",
    "    print ('ROC_flipped: ', roc_chng)\n",
    "    print ('accuracy_result: ',ac_result*100)\n",
    "    print ('accuracy_manipulated_result: ',ac_manipulated*100)\n",
    "    return ac_result*100,ac_manipulated*100\n",
    "\n",
    "\n",
    "# accuracy('fFINAL.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### winner-take-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(point1, point2):\n",
    "    d = np.sum(np.square(point2-point1))\n",
    "    return (np.sqrt(d))\n",
    "\n",
    "def closest_centroids_winner(X, centroid,k):\n",
    "    id_ = np.zeros((X.shape[0],1))\n",
    "    id_ = np.zeros((X.shape[0],1))\n",
    "    #Loop through each data point in X\n",
    "\n",
    "    for x in range(id_.shape[0]):\n",
    "        point = X[x]\n",
    "        #Compare this point to each centroid,\n",
    "        #Keep track of shortest distance and index of shortest distance\n",
    "        min_dist, idx = 255, 0\n",
    "        for i in range(k):\n",
    "            if centroid is None:\n",
    "                random_indices = sample(range(0,X.shape[0]),k)\n",
    "                centroid = np.array([X[i] for i in random_indices])\n",
    "                centroid_ = centroid[i] \n",
    "            elif centroid[i].size==0:\n",
    "                centroid[i] = np.zeros((1,3))\n",
    "                centroid_ = centroid[i] \n",
    "            else:\n",
    "                centroid_ = centroid[i]\n",
    "            dist = euclidean_dist(centroid_,point)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                idx = i\n",
    "#         print (centroid_)\n",
    "        #With the best index found, modify the result idx vector\n",
    "        id_[x] = idx\n",
    "                \n",
    "    return id_\n",
    "\n",
    "\n",
    "# calculate new centroids\n",
    "def new_centroids_winner(X, id_,prev_centroids,k):\n",
    "    prev_cen = prev_centroids[0].tolist()\n",
    "    n = k\n",
    "    new = []\n",
    "    for x in range(n):\n",
    "        a = [X[i] for i in range(X.shape[0]) if id_[i] == x]\n",
    "        new.append(a)\n",
    "    \n",
    "    \n",
    "    new_cen = []\n",
    "    for x in range (n):\n",
    "        new_ = []\n",
    "        for y in new[x]:\n",
    "            part1 = np.array(prev_cen[x])\n",
    "            part2_ = y-part1\n",
    "            part2 = 0.001*part2_\n",
    "            new__ = part1 + (part2)\n",
    "            new_.append(np.array(new__))\n",
    "        mean =  np.array([sum(y)/len(y) for y in new_])\n",
    "#         print (mean)\n",
    "        new_cen.append(mean)\n",
    "#     print (new_cen)\n",
    "    return np.array(new_cen)\n",
    "\n",
    "# Implement winner-take-all all at once\n",
    "def winner_take_all(X, initial_centroids, k, n_iter):\n",
    "    prev_centroids = []\n",
    "    current_centroids = initial_centroids\n",
    "    prev_centroids.append(current_centroids)\n",
    "    prev_cent = np.array(prev_centroids)\n",
    "    id_ = closest_centroids_winner(X,current_centroids,k)\n",
    "    current_centroids = new_centroids_winner(X,id_,prev_centroids,k)\n",
    "    curr_cent = np.array(current_centroids)\n",
    "    \n",
    "    ite = 0\n",
    "    while not np.array_equal (prev_cent,curr_cent) and ite < n_iter:\n",
    "        ite += 1\n",
    "        print (ite)\n",
    "        prev_centroids = []\n",
    "        current_centroids = initial_centroids\n",
    "        prev_centroids.append(current_centroids)\n",
    "        prev_cent = np.array(prev_centroids)\n",
    "        id_ = closest_centroids_winner(X,current_centroids,k)\n",
    "        current_centroids = new_centroids_winner(X,id_,prev_centroids,k)\n",
    "#         print (prev_centroids)\n",
    "        curr_cent = current_centroids\n",
    "\n",
    "#     print (prev_centroids)\n",
    "    return id_, prev_centroids\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"Initialize k random centroids\"\"\"\n",
    "def k_random_centroids(X, k):\n",
    "    random_indices = sample(range(0,X.shape[0]),k)\n",
    "    return np.array([X[i] for i in random_indices])\n",
    "\n",
    "\n",
    "def clustering_winner(A,k,n_iter):\n",
    "    id_, prev_centroids = winner_take_all(A,k_random_centroids(A,k), k,n_iter)\n",
    "    id_ = closest_centroids(A, prev_centroids[-1])\n",
    "    return id_\n",
    "\n",
    "\n",
    "def accuracy_winner (filename):\n",
    "    A,label = openfile(filename)\n",
    "    predictions = clustering_winner (A,2,10)\n",
    "    km_out = [x[0] for x in predictions.tolist()]\n",
    "    km_output_changed = (pd.DataFrame(km_out)).replace([1, 0], [0, 1])\n",
    "    km_output_changed = [x[0] for x in km_output_changed.values.tolist()]\n",
    "    true_label = ground_truth(label)\n",
    "    roc_org = perf_list(true_label, km_out)\n",
    "    roc_chng = perf_list(true_label, km_output_changed)\n",
    "    ac_result = accuracy_score(true_label, km_out)\n",
    "    ac_manipulated = accuracy_score(true_label, km_output_changed)\n",
    "    print ('ROC_org: ', roc_org)\n",
    "    print ('ROC_flipped: ', roc_chng)\n",
    "    print ('accuracy_result: ',ac_result*100)\n",
    "    print ('accuracy_manipulated_result: ',ac_manipulated*100)\n",
    "    return ac_result*100,ac_manipulated*100\n",
    "\n",
    "# accuracy_winner ('cactus_mat.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist_(point1,point2):\n",
    "    difference = point1-point2\n",
    "    if (difference.ndim ==1):\n",
    "        return np.abs(difference)\n",
    "    return np.linalg.norm(difference,axis = 1)\n",
    "\n",
    "# function for SOM\n",
    "def SOM (A, variance, min_eps, max_eps, k):\n",
    "    min_ = 0\n",
    "    max_ = 255\n",
    "    n_iter = 10\n",
    "    sqrt_k = int (np.ceil(np.sqrt(k)))\n",
    "    prev_centroids  = np.array([0 for j in range(len(A))])\n",
    "    new_A = np.array([1 for j in range(len(A))])\n",
    "    \n",
    "    # create grid of centroids\n",
    "    new_centroids = np.array([[np.random.uniform(min_, max_) for i in range (len(A[0]))]for j in range(k)])\n",
    "    indices = np.array([ind for ind in range(k)])\n",
    "\n",
    "    new_centroids = np.array(new_centroids)\n",
    "    ite = 0\n",
    "    while not np.array_equal(prev_centroids,new_A) and ite < n_iter:\n",
    "        prev_centroids = np.copy(new_A)\n",
    "        \n",
    "        ite += 1\n",
    "        print (ite)\n",
    "        epsilon = max_eps*(min_eps/max_eps)**(ite/n_iter)\n",
    "        for i in range(0,len(A)):\n",
    "            distance = euclidean_dist_(new_centroids,A[i])\n",
    "            n = np.column_stack((indices,distance))\n",
    "            n = n[n[:,1].argsort()]\n",
    "            cluster_indices = int(n[0,0])            \n",
    "            n = n[n[:,1] <= variance]\n",
    "            for j in range(len(n)):\n",
    "                phi = np.exp(-np.linalg.norm(new_centroids[int(n[j,0])]-new_centroids[cluster_indices])**2/(2*variance**2))\n",
    "                new_centroids[int(n[j,0])] = new_centroids[int(n[j,0])]+epsilon*phi*(np.subtract(A[i],new_centroids[cluster_indices]))\n",
    "                \n",
    "            new_A [i] = cluster_indices\n",
    "\n",
    "    new_centroids = np.array([[int(np.round(new_centroids[j,i]))for i in range(len(A[0]))]for j in range(k)])\n",
    "    return np.array(new_A),new_centroids\n",
    "    \n",
    "\n",
    "def clustering_SOM(A,k):\n",
    "    new_A,new_centroids = SOM (A, 10.0, 0.0001,0.1,k)\n",
    "    print (new_A)\n",
    "    return new_A\n",
    "\n",
    "def accuracy_som (filename):\n",
    "    A,label = openfile(filename)\n",
    "    km_out = clustering_SOM (A,2)\n",
    "#     print(predictions)\n",
    "#     km_out = [x[0] for x in predictions.tolist()]\n",
    "    km_output_changed = (pd.DataFrame(km_out)).replace([1, 0], [0, 1])\n",
    "    km_output_changed = [x[0] for x in km_output_changed.values.tolist()]\n",
    "    true_label = ground_truth(label)\n",
    "    roc_org = perf_list(true_label, km_out)\n",
    "    roc_chng = perf_list(true_label, km_output_changed)\n",
    "    ac_result = accuracy_score(true_label, km_out)\n",
    "    ac_manipulated = accuracy_score(true_label, km_output_changed)\n",
    "    print ('ROC_org: ', roc_org)\n",
    "    print ('ROC_flipped: ', roc_chng)\n",
    "    print ('accuracy_result: ',ac_result*100)\n",
    "    print ('accuracy_manipulated_result: ',ac_manipulated*100)\n",
    "    return ac_result*100,ac_manipulated*100\n",
    "\n",
    "# accuracy_som('fFINAL.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BKS Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BKS(confusionMat1, confusionMat2,predicted1,predicted2):\n",
    "    clf1 = openfile (confusionMat1)\n",
    "    clf2 = openfile (confusionMat2)\n",
    "    clf1_out = openfile_mpp(predicted1)\n",
    "    clf2_out = openfile(predicted2)\n",
    "    clf1_predicted = [int(x[0]) for x in clf1_out]\n",
    "    clf2_predicted = [int(x[0]) for x in clf2_out]\n",
    "    \n",
    "    class0 = []\n",
    "    for i in range (2):\n",
    "        for x in clf2[0]:\n",
    "            class0.append(int(clf1[0][i])+int(x)) \n",
    "\n",
    "#     print (class0)\n",
    "\n",
    "    class1 = []\n",
    "    for i in range (2):\n",
    "        for x in clf2[1]:\n",
    "            class1.append(int(clf1[1][i])+int(x)) \n",
    "\n",
    "#     print (class1)\n",
    "    \n",
    "    fused_label = np.zeros((1,4))\n",
    "    for i in range (4):\n",
    "        if class0[i] > class1[i]:\n",
    "            fused_label[0,i] = 0\n",
    "        else:\n",
    "            fused_label[0,i] = 1\n",
    "\n",
    "#     print (fused_label)\n",
    "    new_label = np.zeros((len(clf1_predicted),1))\n",
    "\n",
    "    for i in range (len(clf1_predicted)):\n",
    "        if clf1_predicted[i] == 0 and clf2_predicted[i] == 0:\n",
    "            new_label[i,0] = fused_label[0,0]\n",
    "        elif clf1_predicted[i] == 0 and clf2_predicted[i] == 1:\n",
    "            new_label[i,0] = fused_label[0,1]\n",
    "        elif clf1_predicted[i] == 1 and clf2_predicted[i] == 0:\n",
    "            new_label[i,0] = fused_label[0,2]\n",
    "        elif clf1_predicted[i] == 1 and clf2_predicted[i] == 1:\n",
    "            new_label[i,0] = fused_label[0,3]\n",
    "            \n",
    "    return new_label\n",
    "\n",
    "# new_label1 = BKS('f_knn.csv', 'f_dt.csv','f_knn_pred.csv','f_dt_pred.csv')\n",
    "# accuracy_score (testSet, new_label1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
